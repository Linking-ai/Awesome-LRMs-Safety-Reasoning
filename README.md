A curated paper list on **safety in reasoning of Large Reasoning Models (LRMs)**.

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](./LICENSE) ![Static Badge](https://img.shields.io/badge/Contributions-welcome-blue.svg?style=flat) 

## Content

## Keywords Convention

![](https://img.shields.io/badge/ACL2025-orange) Conference

## Papers

- **SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities**  
  *Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, Radha Poovendran*. [[pdf](https://arxiv.org/pdf/2502.12025)], 2025.2.17 ![](https://img.shields.io/badge/Arxiv-orange)