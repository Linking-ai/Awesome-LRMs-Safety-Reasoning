A curated paper list on **safety in reasoning of Large Reasoning Models (LRMs)**.

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](./LICENSE) ![Static Badge](https://img.shields.io/badge/Contributions-welcome-blue.svg?style=flat) 

## Content

## Keywords Convention

![](https://img.shields.io/badge/COCONUT-blue) Abbreviation

![](https://img.shields.io/badge/ACL2025-orange) Conference

![](https://img.shields.io/badge/Analysis-green) Main Features

## Papers

- **SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities**
  *Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo Li, Bill Yuchen Lin, Radha Poovendran*. [[pdf](https://arxiv.org/pdf/2502.12025)], 2025.2.17 ![](https://img.shields.io/badge/Arxiv-orange)
- **Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable**
  *Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Yichang Xu, Ling Liu*. [[pdf](https://arxiv.org/pdf/2503.00555)], 2025.3.1 ![](https://img.shields.io/badge/Arxiv-orange)
- **The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1**
  *Kaiwen Zhou, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, Xin Eric Wang*. [[pdf](https://arxiv.org/abs/2502.12659v3)], 2025.2.27(v3) ![](https://img.shields.io/badge/Arxiv-orange)
- **Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking**
  *Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, Lei Sha*. [[pdf](https://arxiv.org/pdf/2502.12970v1)], 2025.2.18 ![](https://img.shields.io/badge/Arxiv-orange)
- **H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2.0 Flash Thinking**
  *Martin Kuo, Jianyi Zhang, Aolin Ding, Qinsi Wang, Louis DiValentin, Yujia Bao, Wei Wei, Hai Li, Yiran Chen*. [[pdf](https://arxiv.org/pdf/2502.12893)], 2025.2.27(v2) ![](https://img.shields.io/badge/Arxiv-orange)
- **Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models**
  *Meghana Rajeev, Rajkumar Ramamurthy, Prapti Trivedi, Vikas Yadav, Oluwanifemi Bamgbose, Sathwik Tejaswi Madhusudan, James Zou, Nazneen Rajani*. [[pdf](https://arxiv.org/pdf/2503.01781)], 2025.3.3 ![](https://img.shields.io/badge/Arxiv-orange)


## Resources

## Acknowledgements

- We acknowledge that some important works in this field may be missing from this list. We warmly welcome contributions to help us improve!
- If you would like to promote your work or suggest other relevant papers, please feel free to open an issue. Your contributions are greatly appreciated, and we thank you in advance for helping enhance this resource!  
- Special thanks to [Awesome-Efficient-Reasoning](https://github.com/hemingkx/Awesome-Efficient-Reasoning), which inspired the structure and template of this project.